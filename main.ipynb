{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857ee7d5",
   "metadata": {},
   "source": [
    "# 1 Implementing your own Shazam\n",
    "Shazam is a great application that can tell you the title of a song by listening to a short sample. For this first task, we will implement a simplified copy of this app by dealing with hashing algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985cb54c",
   "metadata": {},
   "source": [
    "## 1.1 Getting your data!\n",
    "We will test this part with some query songs which we would like to know the title of (see the file `queries.zip` in the `files` branch of the current repository). To do so we will first need to convert the tracks in the dataset from mp3 format to wav format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839a18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import csv\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b0d1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from sympy import nextprime\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78ae466",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "OFFSET = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3645d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMARK: the files \"queries\" could be saved in a differen path in your local machine\n",
    "# to run this cell change the path accordingly\n",
    "data_folder = Path(\"mp3s-32k\")\n",
    "test_data_folder = Path('queries')\n",
    "\n",
    "new_tracks = test_data_folder.glob('*.wav')\n",
    "\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "856bc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6fcc7cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976af7027a574855baf13441e50d856d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'ffmpeg -i mp3s-32k/metallica/Metallica/01-Enter_Sandman.mp3 mp3s-32k/metallica/Metallica/01-Enter_Sandman.wav' returned non-zero exit status 126.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-23f2ba006a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrack\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp3_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_TRACKS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mconvert_mp3_to_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-9a99e7124937>\u001b[0m in \u001b[0;36mconvert_mp3_to_wav\u001b[0;34m(audio)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mwav_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"wav\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ffmpeg -i {audio} {wav_audio}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwav_audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    416\u001b[0m                **kwargs).stdout\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    517\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'ffmpeg -i mp3s-32k/metallica/Metallica/01-Enter_Sandman.mp3 mp3s-32k/metallica/Metallica/01-Enter_Sandman.wav' returned non-zero exit status 126."
     ]
    }
   ],
   "source": [
    "for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "    convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d74d37",
   "metadata": {},
   "source": [
    "## 1.2 Fingerprint hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86b0fb",
   "metadata": {},
   "source": [
    "We now want to create a representation of our audio signal that allows us to characterize it with respect to its peaks. Once this process is complete, we can adopt a hashing function to get a fingerprint of each song."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84fb1ea",
   "metadata": {},
   "source": [
    "**Utility functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1af46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram_and_peaks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"Plots the spectrogram and peaks \n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def load_audio_peaks(audio, offset, duration, hop_size):\n",
    "    \"\"\"Load the tracks and peaks of an audi\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        offset (float): start reading after this time (in seconds)\n",
    "        duration (float): only load up to this much audio (in seconds)\n",
    "        hop_size (int): the hop_length\n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, offset=offset, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce7cd88",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be tuned\n",
    "DURATION = 30 \n",
    "THRESHOLD = 0\n",
    "\n",
    "# audio files\n",
    "U = []\n",
    "audio_peaks = []\n",
    "for idx, audio in enumerate(tqdm(tracks, total=N_TRACKS)):\n",
    "#     if idx >= 10:\n",
    "#         break\n",
    "    track, sr, onset_env, peaks = load_audio_peaks(audio, OFFSET, DURATION, HOP_SIZE)\n",
    "#     print('Track is: ', track) \n",
    "#     print('sr is: ', sr)\n",
    "#     print('onset_env is: ', onset_env)\n",
    "#     print('peaks is: ', peaks)\n",
    "#     print('audio is: ', audio)\n",
    "    U += list(peaks)\n",
    "    audio_peaks.append((audio, set(peaks)))\n",
    "#   plot_spectrogram_and_peaks(track, sr, peaks, onset_env)\n",
    "        \n",
    "U = set(U)\n",
    "\n",
    "# load new audios\n",
    "new_audio_peaks = []\n",
    "for idx, audio in enumerate(tqdm(new_tracks, total=4)):\n",
    "    track, sr, onset_env, peaks = load_audio_peaks(audio, OFFSET, DURATION, HOP_SIZE)\n",
    "    new_audio_peaks.append((audio, set(peaks)))\n",
    "\n",
    "\n",
    "new_audio_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba4aab",
   "metadata": {},
   "source": [
    "### MinHash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6305af4",
   "metadata": {},
   "source": [
    "We will now implement a **minhash function** from scratch. After that we will read the dataset sequentially and add it to our **MinHash**. The aim is to make our minhash function to map the same song to the same bins. Then we can also define a threshold to control the accuracy of these matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35953fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMARK: MinHash is an approximation of  the Jaccard Similarity\n",
    "def jaccard_similarity(list1, list2):\n",
    "    \"\"\"\n",
    "    :param list1: first set\n",
    "    :param list2: second set\n",
    "    :return: the jaccard similarity between the two sets (it's between 0 and 1)\n",
    "    This function is the function that has to be estimated using the minhashing principle.\n",
    "    \"\"\"\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(set(list1)) + len(set(list2))) - intersection\n",
    "    return float(intersection) / union\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U = list(range(0, 200))\n",
    "def generate_minhash_fns(u, n):\n",
    "    \"\"\"\n",
    "    :param u: total number of peaks (a, b and c should be less than u)\n",
    "    :param n: number of hash functions to generate\n",
    "    :return: an array of hashfunctions (in the form of tuples)\n",
    "    \"\"\"\n",
    "    minhash_functions = []\n",
    "    c = nextprime(u)\n",
    "    for _ in range(n):\n",
    "        a = np.random.randint(u)\n",
    "        b = np.random.randint(u)\n",
    "        minhash_functions.append(np.array([a, b, c]))\n",
    "    return minhash_functions\n",
    "\n",
    "u = len(U)\n",
    "n_minhash_fns = 20\n",
    "#minhash_fns = [np.random.randint(u, size=3) for _ in range(n_minhash_fns)]\n",
    "minhash_fns = generate_minhash_fns(u, n_minhash_fns)\n",
    "print('aaa ', u)\n",
    "\n",
    "\n",
    "def perm(x, a, b, c):\n",
    "    \"\"\"\n",
    "    Simulates permutation using modulus \n",
    "    :param x: int\n",
    "    :param a: param (int)\n",
    "    :param b: param (int)\n",
    "    :param c: param(int)\n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    return (a * x + b) % c\n",
    "\n",
    "\n",
    "def minhash(s, a, b, c):\n",
    "    \"\"\"\n",
    "    :param s: set\n",
    "    :param a: param\n",
    "    :param b: param\n",
    "    :param c: param\n",
    "    :return: the min hash\n",
    "    \"\"\"    \n",
    "    h = [perm(e, a, b, c) for e in s]\n",
    "    mh = min(h)\n",
    "    return mh\n",
    "\n",
    "\n",
    "def minhash_sign(s):\n",
    "    \"\"\"\n",
    "    :param s: set\n",
    "    :return: minhash signature with different minhashes\n",
    "    \"\"\"\n",
    "    minhashes = []\n",
    "    for a, b, c in minhash_fns:\n",
    "        minhashes.append(minhash(s, a, b, c))\n",
    "    return minhashes\n",
    "\n",
    "\n",
    "def minhash_sim(a, b):\n",
    "    \"\"\"\n",
    "    :param a: first set\n",
    "    :param b: second set\n",
    "    :return: estimated Jaccard similarity using minhashing\n",
    "    \"\"\"\n",
    "\n",
    "    sign_a = minhash_sign(a)\n",
    "    sign_b = minhash_sign(b)\n",
    "    l = len(sign_a)\n",
    "    t = 0\n",
    "    for a, b in zip(sign_a, sign_b):\n",
    "        if a == b:\n",
    "            t += 1\n",
    "    return t/l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e62188",
   "metadata": {},
   "source": [
    "### Testing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a76741",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_similarity(new_audio_peaks[0][1], audio_peaks[0][1]) \n",
    "\n",
    "thresholds = [0.6, 0.7, 0.9]\n",
    "for threshold in thresholds:\n",
    "    results = []\n",
    "    for new_audio in tqdm(new_audio_peaks):\n",
    "        max_similarity = -1\n",
    "        most_similar = ''\n",
    "        for audio in audio_peaks:\n",
    "            sim = minhash_sim(new_audio[1], audio[1])\n",
    "            if sim > max_similarity and sim <= threshold:\n",
    "                max_similarity = sim\n",
    "                most_similar = audio[0]\n",
    "        results.append((new_audio[0], most_similar, max_similarity))\n",
    "        print('Results for threshold ', threshold, ' is: ', results)\n",
    "            \n",
    "    \n",
    "\n",
    "results = []\n",
    "for new_audio in tqdm(new_audio_peaks):\n",
    "    max_similarity = -1\n",
    "    most_similar = ''\n",
    "    for audio in audio_peaks:\n",
    "        sim = minhash_sim(new_audio[1], audio[1])\n",
    "        if sim > max_similarity:\n",
    "            max_similarity = sim\n",
    "            most_similar = audio[0]\n",
    "    results.append((new_audio[0], most_similar, max_similarity))\n",
    "            \n",
    "        \n",
    "results\n",
    "\n",
    "print('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46ec84",
   "metadata": {},
   "source": [
    "# 2 Grouping songs together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c55cf72",
   "metadata": {},
   "source": [
    "The final goal of this part is to group songs into similar genres (without using the feature genre in our K-means anaylsis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9e484b",
   "metadata": {},
   "source": [
    "## 2.1  Getting the data and Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c61a8b",
   "metadata": {},
   "source": [
    "We start by reading the datasets we where given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2386b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMARK: the execution of this cell can take a few seconds\n",
    "\n",
    "tracks = pd.read_csv(\"tracks.csv\")\n",
    "echonest = pd.read_csv(\"echonest.csv\")\n",
    "features = pd.read_csv(\"features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94caf66d",
   "metadata": {},
   "source": [
    "**Traks dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2163b",
   "metadata": {},
   "source": [
    "We see that the datasets have many features (e.g. *tracks.csv* has 106574 rows and 53 columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258d9b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tracks.shape)\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3201f9",
   "metadata": {},
   "source": [
    "**Echonest dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ddd54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(echonest.shape)\n",
    "echonest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe0d87c",
   "metadata": {},
   "source": [
    "**Features dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fdf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75af11",
   "metadata": {},
   "source": [
    "### Cleaning of the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a24805",
   "metadata": {},
   "source": [
    "Since the `track_id` seems one of the most important features we check wheter there are missing or duplicate values in these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks[\"track_id\"].isnull().any())\n",
    "print(features[\"track_id\"].isnull().any())\n",
    "print(echonest[\"track_id\"].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tracks.track_id.nunique() == len(tracks[\"track_id\"]):\n",
    "    print(\"No duplicate track ids\")\n",
    "else:\n",
    "    print(\"There are duplicate track ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb93cc66",
   "metadata": {},
   "source": [
    "By exploring the datasets, we've seen that some columns have many NaN values and strange entries (e.g. in `album_information`). For this reason we start filling and cleaning  the datasets. The filling part is done following some rules of thumb (see the `fill` function below):\n",
    "- replace a missing numeric values (as NaN) with the mean of all the numeric values of the same kind\n",
    "- replace all the NaN strings with a blanc space \n",
    "\n",
    "The cleaning part is done by replacing some unpleasant html tags-type-of-strings. For example in the `album_information` column of the `tracks` datasets there are strings like `<p>` we wolud like to eliminate (see the `clean` function below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ff871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(df):\n",
    "    \"\"\"\n",
    "    Input: df, a dataframe\n",
    "    Output: None\n",
    "    Remark: the function performs some trasformations on the columns of the dataframe given in input, in particular:\n",
    "                - if there is a missing numeric value (as NaN) it fills it with an average value\n",
    "                - if there is a string wich is NaN it replaces it with a blanc space \n",
    "    \"\"\"\n",
    "    for i in df.columns:\n",
    "        if df[i].isnull().any() == True:\n",
    "            if is_numeric_dtype(df[i]) == True:\n",
    "                df[i] = df[i].fillna(df[i].mean())\n",
    "            elif is_string_dtype(df[i]) == True:\n",
    "                    df[i] = df[i].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    \"\"\"\n",
    "    Input: df, a dataframe\n",
    "    Output: None\n",
    "    Remark: the function replaces every html substring in the dataframe's columns with a blanc space\n",
    "    \"\"\"\n",
    "    for i in df.columns:\n",
    "            if is_string_dtype(df[i]) == True:\n",
    "                    df[i] = df[i].str.replace(r'<[^<>]*>', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df583434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the datasets in order to keep the original files unchanged\n",
    "cleaned_tracks = tracks.copy()\n",
    "cleaned_echonest = echonest.copy()\n",
    "cleaned_features = features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a17a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill(cleaned_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(cleaned_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17aab43",
   "metadata": {},
   "source": [
    "**Remark .** In 2.2 we will apply PCA and to do so we will need to process and transform the datasets (standardization). In the this phase we will rescale the numeric columns. Since `album_id` and `artist_id` are a fixed number that corresponds to an album and an artist we don't want to change them in the process. This is why we will momentarely drop these features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b133b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tracks = cleaned_tracks.drop([\"album_id\", \"artist_id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_tracks.shape)\n",
    "cleaned_tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220cf1e9",
   "metadata": {},
   "source": [
    "We now will fill and clean the `echonest` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill(cleaned_echonest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(cleaned_echonest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7746cbd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cleaned_echonest.shape)\n",
    "cleaned_echonest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b165",
   "metadata": {},
   "source": [
    "**Remark .** We've decided to drop some columns to reduce the size of the `echonest` dataset. For example we believe that in our analysis `metadata_album_date`, `metadata_album_name` ecc... are not relevant, in particular those features are most of the time empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f259663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_echonest = cleaned_echonest.drop([\"metadata_album_date\", \"metadata_album_name\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422dc362",
   "metadata": {},
   "source": [
    "We now will fill and clean the `features` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill(cleaned_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e8c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(cleaned_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeebc8c",
   "metadata": {},
   "source": [
    "### Merge of the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c2c7ba",
   "metadata": {},
   "source": [
    "As we saw with the exploratory data analysis, the `echonest` dataset has 13.129 unique `track_id`s, while the `features` and `tracks` dataset have 106.574 unique `tracks_id`. The datasets are related to each other:\n",
    "- `echonest` has some information about the audio features, metadata, ranks ecc...\n",
    "- `features` contains many numerical entries that should uniquely characterize the tracks.\n",
    "- `tracks` contains many informations on the album, the artist and the track.\n",
    "\n",
    "Since the datasets have `track_id` in common, we decided to use it as a key to join the datasets. In particular we will merge the datasets w.r.t. `track_id` keeping the `echonest` dataset's rows ($\\sim 13000$ rows). We than fill and clean the dataset as it was done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83baefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tracks and echonest w.r.t. track_id\n",
    "first_merge = cleaned_tracks.merge(cleaned_features, on = \"track_id\")\n",
    "dataset = first_merge.merge(cleaned_echonest, on = \"track_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d313e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85276c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e214d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88076bbe",
   "metadata": {},
   "source": [
    "## 2.2 Choose your features (variables)!\n",
    "We have plenty of features to work with (> 800 columns). So, we will need to find a way to reduce the dimensionality. We will use **PCA** (Principal Component Analysis) for **Dimensionality Reduction**. \n",
    "\n",
    "**Disclamair**. We've gained many insight from https://towardsdatascience.com/principal-component-analysis-for-dimensionality-reduction-115a3d157bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dacadd",
   "metadata": {},
   "source": [
    "Since we would like to apply PCA, first we need to select all the numeric features frome the dataset(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = dataset.select_dtypes([np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54e780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(processed_dataset.shape)\n",
    "processed_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205daf3c",
   "metadata": {},
   "source": [
    "Now we \"standardize\" the features by removing the mean and scaling to unit variance. This transformations can be done using `sklearn preprocessing`, in particular using `sklearn.preprocessing.StandardScaler`.\n",
    "\n",
    "**Remark .** In this preprocessing part we will ignore some features (e.g. `track_id`). Indeed it isn't good to change some fixed features that are related to the ordeting of the songs or the id of the tracks and the albums. Recall that we have already ignored `album_id` and `artist_id` in 2.1. At the end of this processing part we will restore some of the columns we have previously ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133feb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataset can be also be used to carry out some other dimensionality reduction\n",
    "# we will use it for the PCA\n",
    "\n",
    "df = processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e868ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# processed dataset without trak_id as a feature\n",
    "temp_df = pd.DataFrame(scaler.fit_transform(df[df.columns[1:]].values), columns = df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997380e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(final_df.shape)\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c2c4e",
   "metadata": {},
   "source": [
    "**Remark.** In this temporary dataframe there are many columns that we will never use in our future analysis, that is why we drop them. Moreover, by reducing the number of columns we will then have a more accurate clustering (cfr. 2.4) while reducing the number of components in the PCA. If the following columns where not to be dropped the neede components to retain more then 70% of the variance would be 75 instead of 70 and the successive clustering would be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.drop([\"metadata_artist_longitude\", \n",
    "                            \"ranks_artist_discovery_rank\",\n",
    "                            \"ranks_artist_familiarity_rank\",\n",
    "                            \"ranks_artist_hotttnesss_rank\",\n",
    "                            \"ranks_song_currency_rank\",\n",
    "                            \"ranks_song_hotttnesss_rank\",\n",
    "                            \"artist_comments\",\"artist_favorites\",\n",
    "                            \"artist_latitude\",\"track_number\"],\n",
    "                           axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec0094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_df.shape)\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b630d",
   "metadata": {},
   "source": [
    "### PCA with 70 components in order to have > 70% of the total variance \n",
    "We decided to keep this number of features because it is both one order of magnitude less than the original number of features and a big enough to keep a good percentage of the original variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction\n",
    "pca = PCA(n_components=70)\n",
    "df_pca = pca.fit_transform(temp_df)\n",
    "\n",
    "# retained total variance\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the result of PCA into a pandas dataframe\n",
    "# this reduced dataset misses some important features, e.g. track's duration or language\n",
    "# some of those features will be restored in the final_reduced_dataset below\n",
    "final_df_pca = pd.DataFrame(df_pca, columns = ['Feature_%i' % i for i in range(70)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df_pca.shape)\n",
    "final_df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1f26e",
   "metadata": {},
   "source": [
    "### Interpretation of the results\n",
    "By plotting the contribution of each components to the retained total variance we see that the first features contribute the most to the retained variance. We se, for example, that `Feature_0` contributes to the 10.6% of the total variance and uccessive features then contribute lesser and lesser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.plot(pca.explained_variance_ratio_, marker=\".\", markersize=8)\n",
    "plt.ylabel('Retained Variance')\n",
    "plt.xlabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e9db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc94a54",
   "metadata": {},
   "source": [
    "The following plot shows that by increasing the number of retained features the total retained variance increases. It is interesting to note that by keeping just 30 features we would have retained more than the 50% of the total variance. This suggests that many initial features where redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.cumsum(np.round(pca.explained_variance_ratio_,decimals = 3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61524ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.plot(var, marker=\".\", markersize=8)\n",
    "plt.ylabel('Retained Variance')\n",
    "plt.xlabel('number of Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656ed86",
   "metadata": {},
   "source": [
    "### Complete the reduced dataset with useful informations\n",
    "We add back some important features, such as `track_duration` and `track_language_code` which we believe will be useful for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4827f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the final reduced dataset we will use for the K-means \n",
    "final_df_pca = pd.concat([\n",
    "                    dataset.loc[:, [\n",
    "                            'track_id',\n",
    "                            'track_genre_top', \n",
    "                            'track_duration',\n",
    "                            'audio_features_tempo',\n",
    "                            'track_language_code',\n",
    "                            'metadata_artist_location',\n",
    "                            'audio_features_acousticness',\n",
    "                            'audio_features_danceability',\n",
    "                            'audio_features_energy',\n",
    "                            'audio_features_instrumentalness',\n",
    "                            'audio_features_liveness',\n",
    "                            'audio_features_speechiness'\n",
    "                            ]\n",
    "                    ],\n",
    "                    final_df_pca],\n",
    "                    axis = 1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c72c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(final_df_pca.shape)\n",
    "final_df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88de6419",
   "metadata": {},
   "source": [
    "## 2.3 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31c103",
   "metadata": {},
   "source": [
    "We will now implement the *K-means clustering algorithm* (not ++: random initialization) from scratch. Then we will find an optimal number of clusters, running the algorithm on the data from the previous dimensionality reduction. At the end we will use the already implemented version of k-means++ (from the `scikit-learn` library) to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ac085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for kmeans_utils the module \"kneed\" needs to be installed\n",
    "import kmeans_utils as kmu\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b864cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tracks; del echonest; del features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bed50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = final_df_pca.iloc[:, 12:]\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ca9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMARK: the execution of this cell can take a few seconds\n",
    "\n",
    "k, score_results = kmu.get_best_k(kmu.MyKM, df_pca, max_k=8, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best k is:', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705bf5a5",
   "metadata": {},
   "source": [
    "### Comparison between our Kmeans and Scikit-learn Kmeans++\n",
    "**Initialization:** In our kmeans (MyKM) the number of clusters is provided in the fit method and not in the instance creation (i.e.: not imploemented in \\__init\\__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "my_km = kmu.MyKM(n_clusters=4, seed=42)\n",
    "km = KMeans(n_clusters=4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b5327d",
   "metadata": {},
   "source": [
    "**Fitting:** Scikit-learn kmeans is faster than ours implementation. It takes less than 1s to train 10 models whereas our model takes about 10s for a fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8893f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_km.fit(df_pca, info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "print(km.fit(df_pca), 'Computing time:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c114d",
   "metadata": {},
   "source": [
    "**Results:** The labels are different for the two algorithms. In order to compare them we will compare the value of inertia.\n",
    "Our result seems to bu much better , in fact its about 40% than scikit-learn's kmeans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('my_km inertia:', my_km.inertia_)\n",
    "print('km inertia:', km.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be2608",
   "metadata": {},
   "source": [
    "Saving the model for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6747c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.save_model(my_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16aa397",
   "metadata": {},
   "source": [
    "## 2.4 Analysing the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb3a77",
   "metadata": {},
   "source": [
    "Load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3088d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_km = kmu.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005dbf17",
   "metadata": {},
   "source": [
    "Adding the computed labels to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb924e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_pca['labels'] = my_km.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ba702",
   "metadata": {},
   "source": [
    "Check the dataset head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceca91e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002e67b",
   "metadata": {},
   "source": [
    "**1. Language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('track_language_code', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb36d20",
   "metadata": {},
   "source": [
    "**2. Track duration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('track_duration', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e4fa7",
   "metadata": {},
   "source": [
    "**3. Tempo** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8471401",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_tempo', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad3c7f",
   "metadata": {},
   "source": [
    "**4. Acousticness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_acousticness', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617af1de",
   "metadata": {},
   "source": [
    "**5. Danceability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9265a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_danceability', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e352f",
   "metadata": {},
   "source": [
    "**6. Energy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51821c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_energy', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760c57e",
   "metadata": {},
   "source": [
    "**7. Instrumentalness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6735bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_instrumentalness', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b945e26",
   "metadata": {},
   "source": [
    "**8. Liveness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_liveness', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b40f04",
   "metadata": {},
   "source": [
    "**9. Speechiness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ee233",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_speechiness', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce3cb7",
   "metadata": {},
   "source": [
    "### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34854f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('track_genre_top', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a5c1c",
   "metadata": {},
   "source": [
    "###  KMeans++ Analysis\n",
    "Replacing the  MyKM labels with the ones provided by scikit-learn KMeans++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k, score_results = kmu.get_best_k(KMeans, df_pca, max_k=8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26102495",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_opt = KMeans(n_clusters=4, random_state=42).fit(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554272a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_pca['labels'] = km_opt.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06c237",
   "metadata": {},
   "source": [
    "**1. Language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fdc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('track_language_code', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22fc1d7",
   "metadata": {},
   "source": [
    "**2. Track duration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('track_duration', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bff6b6",
   "metadata": {},
   "source": [
    "**3. Tempo** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff018aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_tempo', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1dd6d",
   "metadata": {},
   "source": [
    "**4. Acousticness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52330cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_acousticness', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587bd4c7",
   "metadata": {},
   "source": [
    "**5. Danceability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61bc0ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_danceability', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b11b4",
   "metadata": {},
   "source": [
    "**6. Energy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9122da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_energy', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae6e99",
   "metadata": {},
   "source": [
    "**7. Instrumentalness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e64db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_instrumentalness', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b28500",
   "metadata": {},
   "source": [
    "**8. Liveness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60693c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_liveness', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2152a1d",
   "metadata": {},
   "source": [
    "**9. Speechiness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('audio_features_speechiness', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db23eeb",
   "metadata": {},
   "source": [
    " **10. Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b85571",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu.get_crosstab('track_genre_top', final_df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e024e3",
   "metadata": {},
   "source": [
    "# 3. Algorithmic questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa7d42",
   "metadata": {},
   "source": [
    "Given a list of integers, A, and another integer s. Write an algorithm that outputs all the pairs in A that equal x.\n",
    "\n",
    "*Example* . If $A = [7, -2, 8, 2, 6, 4, -7, 2, 1, 3, -3]$ and $s = 4$, then the algorithm should output: $(7, -3), (-2, 6), (2, 2), (3, 1)$.\n",
    "\n",
    "A **simple solution** is to inspect each element of the list and check if there’s another number in the array which can be added to it to give sum. The simple solution has complexity $O(n^2)$ wich can be improved (e.g. by sorting the array first and than using binary search). A **second and more efficient solution** is given using Hash Tables: \n",
    "- Consider a Hash Table H \n",
    "- For each element $A[i]$ check if $s-A[i]$ is in $H$ \n",
    "\n",
    "The time complexity in this case is $O(n)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a54249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code is shorter then the simple solution\n",
    "# but the complezity is O(n!)\n",
    "from itertools import combinations\n",
    "def algo1(A, s):\n",
    "    a = combinations(A, 2)\n",
    "    return list(filter(lambda x: sum(x) == s, a ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [7, -2, 8, 2, 6, 4, -7, 2, 1, 3, -3] \n",
    "s = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac680967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo1(A, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple solution using an upper triangular matrix\n",
    "# complexity of O(n^2)\n",
    "def algo2(A,s) :\n",
    "    l=[]\n",
    "    for i in range (len(A)-1):\n",
    "        for j in range (i + 1, len(A)):\n",
    "            if (A[i] + A[j] == s):\n",
    "                l.append((A[i] , A[j]))\n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo2(A,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee43fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficient solution with Hash tables\n",
    "# complexity O(n)\n",
    "def algo3(A,s):\n",
    "    count = 0\n",
    "    # the set X will work as an Hash Table for the list A\n",
    "    X = set(A)\n",
    "    # list to keep track of all the pairs with sum s\n",
    "    couples = []\n",
    "    \n",
    "    for item in A:\n",
    "        if s - item in X:\n",
    "            # min and max are used to discard duplicates\n",
    "            couples.append ((min(item, s-item), max(item, s-item)))\n",
    "            count+=1\n",
    "    set_pairs = set(couples)\n",
    "    print (\"Pairs which sum up to \",s,\" are: \", set_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c58693",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo3(A,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb6ade4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
